{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/scratch/cmpe255-sp19/data/pr2/traffic\"\n",
    "color_space = 'YUV' \n",
    "orient = 15  \n",
    "pix_per_cell = 10 \n",
    "cell_per_block = 1 \n",
    "hog_channel = \"ALL\" \n",
    "spatial_size = (40, 40) \n",
    "hist_bins = 40    \n",
    "spatial_feat = True\n",
    "hist_feat = True \n",
    "hog_feat = True \n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLabels(fileName):\n",
    "    labels = []\n",
    "    with open(fileName) as my_file:\n",
    "        for line in my_file:\n",
    "            labels.append(line)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    image_files = sorted([os.path.join(path, file) for file in os.listdir(path)])\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(data):\n",
    "    img = [cv2.imread(i,1) for i in data]\n",
    "    w = 40\n",
    "    h = 40\n",
    "    dimension = (w, h)\n",
    "    result = []\n",
    "    for i in range(len(img)):\n",
    "        res = cv2.resize(img[i], dimension, interpolation=cv2.INTER_CUBIC)\n",
    "        result.append(res)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_features_descriptor(img, orient, pix_per_cell, cell_per_block):\n",
    "    features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=False,\n",
    "                       visualise=False, feature_vector=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    yuv_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    car_ch1 = yuv_image[:,:,0]\n",
    "    hog_features = hog_features_descriptor(car_ch1, orient, pix_per_cell, cell_per_block)\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_of_dataset(dataset):\n",
    "    hog_features = []\n",
    "    for image in dataset:\n",
    "        hog_features.append(extract_features(image))\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = loadImages(data_path+\"/train\")\n",
    "test_images = loadImages(data_path+\"/test\")\n",
    "train_labels = loadLabels(data_path+\"/train.labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_images = image_processing(train_images)\n",
    "test_set_images = image_processing(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=21)\n",
    "# principalComponents_train = pca.fit_transform(train_set_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA().fit(train_set_images)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=21)\n",
    "# principalComponents_test = pca.fit_transform(test_set_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA().fit(test_set_images)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/013825292/.local/lib/python3.7/site-packages/skimage/feature/_hog.py:239: skimage_deprecation: Argument `visualise` is deprecated and will be changed to `visualize` in v0.16\n",
      "  'be changed to `visualize` in v0.16', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "train_set_hog_features = extract_features_of_dataset(train_set_images)\n",
    "test_set_hog_features = extract_features_of_dataset(test_set_images)\n",
    "X_train = np.array(train_set_hog_features)\n",
    "y_train = np.array(train_labels)\n",
    "X_test = np.array(test_set_hog_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "# f= open(\"prd.dat\",\"w+\")\n",
    "# for i in y_pred:\n",
    "#     f.write(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1\\n', '1\\n', '1\\n', ..., '1\\n', '1\\n', '14\\n'], dtype='<U3')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_file = open(\"prp.dat\",\"w\")\n",
    "for label in y_pred:\n",
    "    predictions_file.write(str(int(label)))\n",
    "    predictions_file.write(\"\\n\")\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rndm_clf = RandomForestClassifier(class_weight=None, criterion='gini', max_features='auto', min_impurity_split=None,\n",
    "#             min_samples_leaf=1, min_samples_split=2,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=300,random_state=0, verbose=0)\n",
    "# rndm_clf = rndm_clf.fit(X_train, y_train)\n",
    "# y_pred_rand = rndm_clf.predict(X_test)\n",
    "# #print(classification_report(test_labels, y_pred_rand)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(100, 4), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=400, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# clf.fit(principalComponents, train_labels)\n",
    "\n",
    "# y_pred_ann = clf.predict(principalComponents_test)\n",
    "# print(classification_report(test_labels, y_pred_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# clf = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "# clf = clf.fit(principalComponents, train_labels)\n",
    "# y_pred_svd = clf.predict(principalComponents_test)\n",
    "# print(classification_report(test_labels, y_pred_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# xg_reg = xgb.XGBClassifier(objective ='multi:softmax' ,learning_rate = 0.63, \n",
    "#                           max_depth = 6, n_estimators = 400, num_class = 12)\n",
    "# xg_reg.fit(principalComponents,train_labels)\n",
    "# preds = xg_reg.predict(principalComponents_test)\n",
    "# print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tried On Traffic Small Dataset in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import to_categorical\n",
    "# from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels_ = np.loadtxt('/Users/Rutul Thakkar/Desktop/Sjsu Jupyter/CMPE255/Program2/traffic/traffic-small/train.labels')\n",
    "# train_labels = pd.DataFrame(train_labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob   \n",
    "# train_path  = '/Users/Rutul Thakkar/Desktop/Sjsu Jupyter/CMPE255/Program2/traffic/traffic-small/train/*.jpg'\n",
    "# train_files=glob.glob(train_path)\n",
    "\n",
    "# train_image = []\n",
    "# for train_file in train_files:\n",
    "#     img = image.load_img(train_file, target_size=(28,28,1), grayscale=True)\n",
    "#     img = image.img_to_array(img)\n",
    "#     img = img/255\n",
    "#     train_image.append(img)\n",
    "# X = np.array(train_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = to_categorical(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = '/Users/Rutul Thakkar/Desktop/Sjsu Jupyter/CMPE255/Program2/traffic/traffic-small/test/*.jpg'\n",
    "# test_files=glob.glob(path)\n",
    "\n",
    "# test_image = []\n",
    "# for test_file in test_files:\n",
    "#     img = image.load_img(test_file, target_size=(28,28,1), grayscale=True)\n",
    "#     img = image.img_to_array(img)\n",
    "#     img = img/255\n",
    "#     test_image.append(img)\n",
    "# test = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(15, activation='softmax'))\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "# model.fit(X, train_labels,batch_size= 100 ,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict_classes(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_labels = to_categorical(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels_ = np.loadtxt('/Users/Rutul Thakkar/Desktop/Sjsu Jupyter/CMPE255/Program2/traffic/traffic-small/test.labels')\n",
    "# test_labels_ = pd.DataFrame(test_labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = to_categorical(test_labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# f1 = f1_score(test_labels, prediction_labels, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
